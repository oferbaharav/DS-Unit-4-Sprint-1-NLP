{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "##### Your Code Here #####\n",
    "data = pd.read_csv('./data/job_listings.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ability to communicate Model findings to both Technical and Non-Technical stake holders&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hands on experience in SQL/Hive or similar programming language&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Must show past work via GitHub, Kaggle or any other published article&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\\nApply Now&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;\"</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\n</li><li><p>Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\nApply Now</div></div></div></div></div></div></div><div></div>\"   \n",
       "\n",
       "             title  \n",
       "0  Data scientistÂ   "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 0)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cleaned_text = []\n",
    "\n",
    "\"\"\" Make souped \"\"\"\n",
    "for description in data.description:\n",
    "    soup = BeautifulSoup(description)\n",
    "    text = soup.get_text(strip=True)\n",
    "    text = re.sub(\"\\\\\\\\n\", ' ', text)\n",
    "    #noticed below that commas were left out so stripping them\n",
    "    text = re.sub(r'[,.!?():;]', '', text)\n",
    "    text = re.sub(r'/', ' ', text)\n",
    "    cleaned_text.append(text)\n",
    "\n",
    "data['cleaned_text'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ability to communicate Model findings to both Technical and Non-Technical stake holders&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hands on experience in SQL/Hive or similar programming language&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Must show past work via GitHub, Kaggle or any other published article&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\\nApply Now&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;\"</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"</td>\n",
       "      <td>[b\"Job, Requirements:, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. You will do so by empowering and improving the next generation of Accolade Applications and user experiences.&lt;/p&gt;&lt;p&gt;&lt;b&gt;\\nA day in the life\\xe2\\x80\\xa6&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\\nWork with a small agile team to design and develop mobile applications in an iterative fashion.&lt;/li&gt;&lt;li&gt;\\nWork with a tight-knit group of development team members in Seattle.&lt;/li&gt;&lt;li&gt;\\nContribute to best practices and help guide the future of our applications.&lt;/li&gt;&lt;li&gt;\\nOperates effectively as a collaborative member of the development team.&lt;/li&gt;&lt;li&gt;\\nOperates effectively as an individual for quick turnaround of enhancements and fixes.&lt;/li&gt;&lt;li&gt;\\nResponsible for meeting expectations and deliverables on time with high quality.&lt;/li&gt;&lt;li&gt;\\nDrive and implement new features within our mobile applications.&lt;/li&gt;&lt;li&gt;\\nPerform thorough manual testing and writing test cases that cover all areas.&lt;/li&gt;&lt;li&gt;\\nIdentify new development tools/approaches that will increase code quality, efficiency, and best practices.&lt;/li&gt;&lt;li&gt;\\nDevelop and champion the the development processes, coding style guidelines, and architectural designs necessary to innovate and maintain great product quality.&lt;/li&gt;&lt;li&gt;\\nEffectively turns design documents and graphics into performant, usable UI.&lt;/li&gt;&lt;li&gt;\\nDemonstrates creative, technical, and analytical skills.&lt;/li&gt;&lt;li&gt;\\nDemonstrates ability to communicate effectively in both technical and business environments&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;\\n&lt;br/&gt;\\n&lt;div&gt;Qualifications&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;&lt;b&gt;What we are looking for\\xe2\\x80\\xa6&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\\nMaster\\xe2\\x80\\x99s Degree in Computer Science, Math, or related field.&lt;/li&gt;&lt;li&gt;\\nComputer Science fundamentals, as illustrated through algorithm design, problem solving, and complexity analysis.&lt;/li&gt;&lt;li&gt;\\nMust have 1+ year real-world experience developing and deploying micro-services or data pipelines&lt;/li&gt;&lt;li&gt;\\nMust have a fundamental understanding of key machine learning concepts, such as accuracy measures, cross-validation, and open source machine learning libraries&lt;/li&gt;&lt;li&gt;\\nFluent in Python and SQL&lt;/li&gt;&lt;li&gt;\\nProficient with writing unit/functional tests and familiar with automation frameworks&lt;/li&gt;&lt;li&gt;\\nExperience with cloud infrastructure, such as AWS or Azure, is a plus.&lt;/li&gt;&lt;li&gt;\\nExperience with distributed data pipelines, such as a Spark, is a plus.&lt;/li&gt;&lt;li&gt;\\nStrong written and oral communication skills.&lt;/li&gt;&lt;li&gt;\\nDesire and willingness to work in an Agile, collaborative, innovative, flexible, and team-oriented environment&lt;/li&gt;&lt;li&gt;\\nHands-on, detail-oriented, methodical &amp;amp; inquisitive&lt;/li&gt;&lt;li&gt;\\nA motivated self-starter with a solid level of experience that quickly grasps complex challenges&lt;/li&gt;&lt;li&gt;\\nA skillful communicator with experience working with technical management teams&lt;/li&gt;&lt;li&gt;\\n A service oriented person who thinks \"Customer First\"&lt;/li&gt;&lt;li&gt;\\nFast fail entrepreneurial spirit&lt;/li&gt;&lt;li&gt;\\nThrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high&lt;/li&gt;&lt;li&gt;\\nExcited by the challenges of working in a product team undergoing rapid, international growth&lt;/li&gt;&lt;/ul&gt;&lt;br/&gt;\\nAdditional Information&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;&lt;b&gt;What is important to us&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\\nCreating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees, members and customers. The secret to our success is:&lt;/p&gt;&lt;p&gt;&lt;b&gt;\\nWe find joy and purpose in serving others&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\\nMaking a difference in our members\\xe2\\x80\\x99 and customers\\xe2\\x80\\x99 lives is what we do. Even when it\\xe2\\x80\\x99s hard, we do the right thing for the right reasons.&lt;/p&gt;&lt;p&gt;&lt;b&gt;\\nWe are strong individually and together, we\\xe2\\x80\\x99re powerful&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\\nTrusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways, having fun along the way.&lt;/p&gt;&lt;p&gt;&lt;b&gt;\\nWe roll up our sleeves and get stuff done&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\\nResults motivate us. And we aren\\'t afraid of the hard work or tough decisions needed to get us there.&lt;/p&gt;&lt;p&gt;&lt;b&gt;\\nWe\\xe2\\x80\\x99re boldly and relentlessly reinventing healthcare&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\\nWe\\'re curious and act big - not afraid to knock down barriers or take calculated risks to change the world, one person at a time.&lt;/p&gt;&lt;p&gt;\\nAll your information will be kept confidential according to EEO guidelines.&lt;/p&gt;&lt;/div&gt;'</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>b'Job Description  As a Data Scientist 1 you will help us build machine learning models data pipelines and micro-services to help our clients navigate their healthcare journey You will do so by empowering and improving the next generation of Accolade Applications and user experiences A day in the life\\xe2\\x80\\xa6 Work with a small agile team to design and develop mobile applications in an iterative fashion Work with a tight-knit group of development team members in Seattle Contribute to best practices and help guide the future of our applications Operates effectively as a collaborative member of the development team Operates effectively as an individual for quick turnaround of enhancements and fixes Responsible for meeting expectations and deliverables on time with high quality Drive and implement new features within our mobile applications Perform thorough manual testing and writing test cases that cover all areas Identify new development tools approaches that will increase code quality efficiency and best practices Develop and champion the the development processes coding style guidelines and architectural designs necessary to innovate and maintain great product quality Effectively turns design documents and graphics into performant usable UI Demonstrates creative technical and analytical skills Demonstrates ability to communicate effectively in both technical and business environments  Qualifications  What we are looking for\\xe2\\x80\\xa6 Master\\xe2\\x80\\x99s Degree in Computer Science Math or related field Computer Science fundamentals as illustrated through algorithm design problem solving and complexity analysis Must have 1+ year real-world experience developing and deploying micro-services or data pipelines Must have a fundamental understanding of key machine learning concepts such as accuracy measures cross-validation and open source machine learning libraries Fluent in Python and SQL Proficient with writing unit functional tests and familiar with automation frameworks Experience with cloud infrastructure such as AWS or Azure is a plus Experience with distributed data pipelines such as a Spark is a plus Strong written and oral communication skills Desire and willingness to work in an Agile collaborative innovative flexible and team-oriented environment Hands-on detail-oriented methodical &amp; inquisitive A motivated self-starter with a solid level of experience that quickly grasps complex challenges A skillful communicator with experience working with technical management teams  A service oriented person who thinks \"Customer First\" Fast fail entrepreneurial spirit Thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high Excited by the challenges of working in a product team undergoing rapid international growth Additional Information  What is important to us Creating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees members and customers The secret to our success is We find joy and purpose in serving others Making a difference in our members\\xe2\\x80\\x99 and customers\\xe2\\x80\\x99 lives is what we do Even when it\\xe2\\x80\\x99s hard we do the right thing for the right reasons We are strong individually and together we\\xe2\\x80\\x99re powerful Trusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways having fun along the way We roll up our sleeves and get stuff done Results motivate us And we aren\\'t afraid of the hard work or tough decisions needed to get us there We\\xe2\\x80\\x99re boldly and relentlessly reinventing healthcare We\\'re curious and act big - not afraid to knock down barriers or take calculated risks to change the world one person at a time All your information will be kept confidential according to EEO guidelines'</td>\n",
       "      <td>[b'Job, Description,  , Data, Scientist, 1, help, build, machine, learn, model, datum, pipeline, micro-services, help, client, navigate, healthcare, journey, empower, improve, generation, Accolade, Applications, user, experience, day, life\\xe2\\x80\\xa6, Work, small, agile, team, design, develop, mobile, application, iterative, fashion, Work, tight-knit, group, development, team, member, Seattle, Contribute, well, practice, help, guide, future, application, Operates, effectively, collaborative, member, development, team, Operates, effectively, individual, quick, turnaround, enhancement, fix, Responsible, meet, expectation, deliverable, time, high, quality, Drive, implement, new, feature, mobile, application, Perform, thorough, manual, test, write, test, case, cover, area, Identify, new, development, tool, approach, increase, code, quality, efficiency, well, practice, Develop, champion, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "1  1            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\n</li><li><p>Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\nApply Now</div></div></div></div></div></div></div><div></div>\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. You will do so by empowering and improving the next generation of Accolade Applications and user experiences.</p><p><b>\\nA day in the life\\xe2\\x80\\xa6</b></p><ul><li>\\nWork with a small agile team to design and develop mobile applications in an iterative fashion.</li><li>\\nWork with a tight-knit group of development team members in Seattle.</li><li>\\nContribute to best practices and help guide the future of our applications.</li><li>\\nOperates effectively as a collaborative member of the development team.</li><li>\\nOperates effectively as an individual for quick turnaround of enhancements and fixes.</li><li>\\nResponsible for meeting expectations and deliverables on time with high quality.</li><li>\\nDrive and implement new features within our mobile applications.</li><li>\\nPerform thorough manual testing and writing test cases that cover all areas.</li><li>\\nIdentify new development tools/approaches that will increase code quality, efficiency, and best practices.</li><li>\\nDevelop and champion the the development processes, coding style guidelines, and architectural designs necessary to innovate and maintain great product quality.</li><li>\\nEffectively turns design documents and graphics into performant, usable UI.</li><li>\\nDemonstrates creative, technical, and analytical skills.</li><li>\\nDemonstrates ability to communicate effectively in both technical and business environments</li></ul></div>\\n<br/>\\n<div>Qualifications<br/>\\n<br/>\\n<p><b>What we are looking for\\xe2\\x80\\xa6</b></p><ul><li>\\nMaster\\xe2\\x80\\x99s Degree in Computer Science, Math, or related field.</li><li>\\nComputer Science fundamentals, as illustrated through algorithm design, problem solving, and complexity analysis.</li><li>\\nMust have 1+ year real-world experience developing and deploying micro-services or data pipelines</li><li>\\nMust have a fundamental understanding of key machine learning concepts, such as accuracy measures, cross-validation, and open source machine learning libraries</li><li>\\nFluent in Python and SQL</li><li>\\nProficient with writing unit/functional tests and familiar with automation frameworks</li><li>\\nExperience with cloud infrastructure, such as AWS or Azure, is a plus.</li><li>\\nExperience with distributed data pipelines, such as a Spark, is a plus.</li><li>\\nStrong written and oral communication skills.</li><li>\\nDesire and willingness to work in an Agile, collaborative, innovative, flexible, and team-oriented environment</li><li>\\nHands-on, detail-oriented, methodical &amp; inquisitive</li><li>\\nA motivated self-starter with a solid level of experience that quickly grasps complex challenges</li><li>\\nA skillful communicator with experience working with technical management teams</li><li>\\n A service oriented person who thinks \"Customer First\"</li><li>\\nFast fail entrepreneurial spirit</li><li>\\nThrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high</li><li>\\nExcited by the challenges of working in a product team undergoing rapid, international growth</li></ul><br/>\\nAdditional Information<br/>\\n<br/>\\n<p><b>What is important to us</b></p><p>\\nCreating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees, members and customers. The secret to our success is:</p><p><b>\\nWe find joy and purpose in serving others</b></p><p>\\nMaking a difference in our members\\xe2\\x80\\x99 and customers\\xe2\\x80\\x99 lives is what we do. Even when it\\xe2\\x80\\x99s hard, we do the right thing for the right reasons.</p><p><b>\\nWe are strong individually and together, we\\xe2\\x80\\x99re powerful</b></p><p>\\nTrusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways, having fun along the way.</p><p><b>\\nWe roll up our sleeves and get stuff done</b></p><p>\\nResults motivate us. And we aren\\'t afraid of the hard work or tough decisions needed to get us there.</p><p><b>\\nWe\\xe2\\x80\\x99re boldly and relentlessly reinventing healthcare</b></p><p>\\nWe\\'re curious and act big - not afraid to knock down barriers or take calculated risks to change the world, one person at a time.</p><p>\\nAll your information will be kept confidential according to EEO guidelines.</p></div>'   \n",
       "\n",
       "              title  \\\n",
       "0  Data scientistÂ     \n",
       "1  Data Scientist I   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  cleaned_text  \\\n",
       "0  b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1  b'Job Description  As a Data Scientist 1 you will help us build machine learning models data pipelines and micro-services to help our clients navigate their healthcare journey You will do so by empowering and improving the next generation of Accolade Applications and user experiences A day in the life\\xe2\\x80\\xa6 Work with a small agile team to design and develop mobile applications in an iterative fashion Work with a tight-knit group of development team members in Seattle Contribute to best practices and help guide the future of our applications Operates effectively as a collaborative member of the development team Operates effectively as an individual for quick turnaround of enhancements and fixes Responsible for meeting expectations and deliverables on time with high quality Drive and implement new features within our mobile applications Perform thorough manual testing and writing test cases that cover all areas Identify new development tools approaches that will increase code quality efficiency and best practices Develop and champion the the development processes coding style guidelines and architectural designs necessary to innovate and maintain great product quality Effectively turns design documents and graphics into performant usable UI Demonstrates creative technical and analytical skills Demonstrates ability to communicate effectively in both technical and business environments  Qualifications  What we are looking for\\xe2\\x80\\xa6 Master\\xe2\\x80\\x99s Degree in Computer Science Math or related field Computer Science fundamentals as illustrated through algorithm design problem solving and complexity analysis Must have 1+ year real-world experience developing and deploying micro-services or data pipelines Must have a fundamental understanding of key machine learning concepts such as accuracy measures cross-validation and open source machine learning libraries Fluent in Python and SQL Proficient with writing unit functional tests and familiar with automation frameworks Experience with cloud infrastructure such as AWS or Azure is a plus Experience with distributed data pipelines such as a Spark is a plus Strong written and oral communication skills Desire and willingness to work in an Agile collaborative innovative flexible and team-oriented environment Hands-on detail-oriented methodical & inquisitive A motivated self-starter with a solid level of experience that quickly grasps complex challenges A skillful communicator with experience working with technical management teams  A service oriented person who thinks \"Customer First\" Fast fail entrepreneurial spirit Thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high Excited by the challenges of working in a product team undergoing rapid international growth Additional Information  What is important to us Creating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees members and customers The secret to our success is We find joy and purpose in serving others Making a difference in our members\\xe2\\x80\\x99 and customers\\xe2\\x80\\x99 lives is what we do Even when it\\xe2\\x80\\x99s hard we do the right thing for the right reasons We are strong individually and together we\\xe2\\x80\\x99re powerful Trusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways having fun along the way We roll up our sleeves and get stuff done Results motivate us And we aren\\'t afraid of the hard work or tough decisions needed to get us there We\\xe2\\x80\\x99re boldly and relentlessly reinventing healthcare We\\'re curious and act big - not afraid to knock down barriers or take calculated risks to change the world one person at a time All your information will be kept confidential according to EEO guidelines'   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  tokens  \n",
       "0  [b\"Job, Requirements:, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]                                                                                                                                                             \n",
       "1  [b'Job, Description,  , Data, Scientist, 1, help, build, machine, learn, model, datum, pipeline, micro-services, help, client, navigate, healthcare, journey, empower, improve, generation, Accolade, Applications, user, experience, day, life\\xe2\\x80\\xa6, Work, small, agile, team, design, develop, mobile, application, iterative, fashion, Work, tight-knit, group, development, team, member, Seattle, Contribute, well, practice, help, guide, future, application, Operates, effectively, collaborative, member, development, team, Operates, effectively, individual, quick, turnaround, enhancement, fix, Responsible, meet, expectation, deliverable, time, high, quality, Drive, implement, new, feature, mobile, application, Perform, thorough, manual, test, write, test, case, cover, area, Identify, new, development, tool, approach, increase, code, quality, efficiency, well, practice, Develop, champion, ...]  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['requirement', 'conceptual', 'understanding', 'Machine', 'Learning', 'model', 'like', 'Bayes', 'K', 'mean', 'SVM', 'Apriori', 'Logistic', 'Regression', 'Neural', 'Random', 'Forests', 'Decision', 'Trees', 'K', 'NN', 'hand', 'experience', 'Intermediate', 'expert', 'level', 'coding', 'skill', 'Python', 'ability', 'write', 'function', 'clean', 'efficient', 'datum', 'manipulation', 'mandatory', 'role', 'exposure', 'package', 'like', 'NumPy', 'SciPy', 'Pandas', 'Matplotlib', 'etc', 'Python', 'dplyr', 'tidyR', 'r', 'ability', 'communicate', 'Model', 'finding', 'Technical', 'Non', 'technical', 'stake', 'holder', 'hand', 'experience', 'SQL', 'Hive', 'similar', 'programming', 'language', 'past', 'work', 'GitHub', 'Kaggle', 'publish', 'article', 'Master', 'degree', 'Statistics', 'Mathematics', 'Computer', 'Science', 'quant', 'specific', 'field', 'apply']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(data.cleaned_text[0])\n",
    "print([token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True) and (token.is_alpha ==True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Tokenizer Pipe\n",
    "# make tokens\n",
    "\n",
    "\n",
    "tokens = []\n",
    "\n",
    "\n",
    "for doc in tokenizer.pipe(data.cleaned_text, batch_size=500):\n",
    "    doc_tokens = [token.lemma_ for token in doc if (token.is_stop != True) \n",
    "                  and (token.is_punct != True)]\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "data['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of what's inside nlp.vocab, uncomment line below, gets you all the vocab in cleaned_text\n",
    "#list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ability to communicate Model findings to both Technical and Non-Technical stake holders&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hands on experience in SQL/Hive or similar programming language&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Must show past work via GitHub, Kaggle or any other published article&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\\nApply Now&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;\"</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"</td>\n",
       "      <td>[b\"Job, Requirements, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\n</li><li><p>Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\nApply Now</div></div></div></div></div></div></div><div></div>\"   \n",
       "\n",
       "             title  \\\n",
       "0  Data scientistÂ    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                cleaned_text  \\\n",
       "0  b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tokens  \n",
       "0  [b\"Job, Requirements, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 7640)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "# Classics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# list of text documents\n",
    "data['tokens_joined'] = data.tokens.apply(lambda x: ' '.join(x))\n",
    "text = data.tokens_joined\n",
    "\n",
    "# create the transformer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# build vocab\n",
    "vect.fit(text)\n",
    "\n",
    "# transform text\n",
    "dtm = vect.transform(text)\n",
    "dtm.shape\n",
    "\n",
    "# Create a Vocabulary\n",
    "# The vocabulary establishes all of the possible words that we might use.\n",
    "\n",
    "# The vocabulary dictionary does not represent the counts of words!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ability to communicate Model findings to both Technical and Non-Technical stake holders&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hands on experience in SQL/Hive or similar programming language&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Must show past work via GitHub, Kaggle or any other published article&lt;/p&gt;\\n&lt;/li&gt;&lt;li&gt;&lt;p&gt;Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;\\nApply Now&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;\"</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"</td>\n",
       "      <td>[b\"Job, Requirements, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]</td>\n",
       "      <td>b\"Job Requirements Conceptual understand Machine Learning model like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear   Logistic Regression Neural Random Forests Decision Trees K-NN hands-on experience 2 Intermediate expert level code skill Python R Ability write function clean efficient datum manipulation mandatory role Exposure package like NumPy SciPy Pandas Matplotlib etc Python GGPlot2 dplyr tidyR R Ability communicate Model finding Technical Non-Technical stake holder Hands experience SQL Hive similar programme language past work GitHub Kaggle publish article Master's degree Statistics Mathematics Computer Science quant specific field Apply Now\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\n</li><li><p>Master's degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\nApply Now</div></div></div></div></div></div></div><div></div>\"   \n",
       "\n",
       "             title  \\\n",
       "0  Data scientistÂ    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                cleaned_text  \\\n",
       "0  b\"Job Requirements Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear  Logistic Regression Neural Random Forests Decision Trees K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R Ability to write functions clean and efficient data manipulation are mandatory for this role Exposure to packages like NumPy SciPy Pandas Matplotlib etc in Python or GGPlot2 dplyr tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub Kaggle or any other published article Master's degree in Statistics Mathematics Computer Science or any other quant specific field Apply Now\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tokens  \\\n",
       "0  [b\"Job, Requirements, Conceptual, understand, Machine, Learning, model, like, Nai\\xc2\\xa8ve, Bayes, K-Means, SVM, Apriori, Linear,  , Logistic, Regression, Neural, Random, Forests, Decision, Trees, K-NN, hands-on, experience, 2, Intermediate, expert, level, code, skill, Python, R, Ability, write, function, clean, efficient, datum, manipulation, mandatory, role, Exposure, package, like, NumPy, SciPy, Pandas, Matplotlib, etc, Python, GGPlot2, dplyr, tidyR, R, Ability, communicate, Model, finding, Technical, Non-Technical, stake, holder, Hands, experience, SQL, Hive, similar, programme, language, past, work, GitHub, Kaggle, publish, article, Master's, degree, Statistics, Mathematics, Computer, Science, quant, specific, field, Apply, Now\"]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tokens_joined  \n",
       "0  b\"Job Requirements Conceptual understand Machine Learning model like Nai\\xc2\\xa8ve Bayes K-Means SVM Apriori Linear   Logistic Regression Neural Random Forests Decision Trees K-NN hands-on experience 2 Intermediate expert level code skill Python R Ability write function clean efficient datum manipulation mandatory role Exposure package like NumPy SciPy Pandas Matplotlib etc Python GGPlot2 dplyr tidyR R Ability communicate Model finding Technical Non-Technical stake holder Hands experience SQL Hive similar programme language past work GitHub Kaggle publish article Master's degree Statistics Mathematics Computer Science quant specific field Apply Now\"  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>02115</th>\n",
       "      <th>0305</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zogsports</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows Ã 7640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  02115  0305  0356  04  06366  08  10  100  1000  ...  zero  zeus  zf  \\\n",
       "0    0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "1    0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "2    0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "3    0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "4    0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "..  ..  ..     ..    ..    ..  ..     ..  ..  ..   ..     ... ..    ..    ..    \n",
       "421  0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "422  0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "423  0   0      0     0     0   0      0   0   0    0     ...  1     0     0    \n",
       "424  0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "425  0   0      0     0     0   0      0   0   0    0     ...  0     0     0    \n",
       "\n",
       "     zheng  zillow  zogsports  zone  zoom  zuckerberg  zurich  \n",
       "0    0      0       0          0     0     0           0       \n",
       "1    0      0       0          0     0     0           0       \n",
       "2    0      0       0          0     0     0           0       \n",
       "3    1      0       0          0     0     0           0       \n",
       "4    0      0       0          0     0     0           0       \n",
       "..  ..     ..      ..         ..    ..    ..          ..       \n",
       "421  0      0       0          0     0     0           0       \n",
       "422  0      0       0          0     0     0           0       \n",
       "423  0      0       0          0     0     0           0       \n",
       "424  0      0       0          0     0     0           0       \n",
       "425  0      0       0          0     0     0           0       \n",
       "\n",
       "[426 rows x 7640 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Word Counts for each document\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "doc_len = [len(doc) for doc in data.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(doc_len);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 1174)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2019</th>\n",
       "      <th>401k</th>\n",
       "      <th>ability</th>\n",
       "      <th>ability communicate</th>\n",
       "      <th>ability work</th>\n",
       "      <th>able</th>\n",
       "      <th>able work</th>\n",
       "      <th>academic</th>\n",
       "      <th>...</th>\n",
       "      <th>x9d</th>\n",
       "      <th>xe2</th>\n",
       "      <th>xe2 x80</th>\n",
       "      <th>year</th>\n",
       "      <th>year experience</th>\n",
       "      <th>year relevant</th>\n",
       "      <th>year work</th>\n",
       "      <th>years</th>\n",
       "      <th>years xe2</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134870</td>\n",
       "      <td>0.165729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.063915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178610</td>\n",
       "      <td>0.179045</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105283</td>\n",
       "      <td>0.105539</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100  2019  401k   ability  ability communicate  ability work  able  \\\n",
       "0  0.0  0.0  0.0   0.0   0.134870  0.165729             0.0           0.0    \n",
       "1  0.0  0.0  0.0   0.0   0.026007  0.063915             0.0           0.0    \n",
       "2  0.0  0.0  0.0   0.0   0.068303  0.000000             0.0           0.0    \n",
       "3  0.0  0.0  0.0   0.0   0.000000  0.000000             0.0           0.0    \n",
       "4  0.0  0.0  0.0   0.0   0.000000  0.000000             0.0           0.0    \n",
       "\n",
       "   able work  academic  ...  x9d       xe2   xe2 x80      year  \\\n",
       "0  0.0        0.0       ...  0.0  0.000000  0.000000  0.000000   \n",
       "1  0.0        0.0       ...  0.0  0.178610  0.179045  0.023859   \n",
       "2  0.0        0.0       ...  0.0  0.000000  0.000000  0.000000   \n",
       "3  0.0        0.0       ...  0.0  0.000000  0.000000  0.039239   \n",
       "4  0.0        0.0       ...  0.0  0.105283  0.105539  0.112511   \n",
       "\n",
       "   year experience  year relevant  year work  years  years xe2  york  \n",
       "0  0.0              0.0            0.0        0.0    0.0        0.0   \n",
       "1  0.0              0.0            0.0        0.0    0.0        0.0   \n",
       "2  0.0              0.0            0.0        0.0    0.0        0.0   \n",
       "3  0.0              0.0            0.0        0.0    0.0        0.0   \n",
       "4  0.0              0.0            0.0        0.0    0.0        0.0   \n",
       "\n",
       "[5 rows x 1174 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                         #tokenizer = tokenize,\n",
    "                         ngram_range = (1,2),\n",
    "                         min_df = 0.05, \n",
    "                         max_df = 0.8,\n",
    "                         max_features = 5000\n",
    "                       )\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(data.tokens_joined)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "print(dtm.shape)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = [\"\"\"\n",
    "OFER BAHARAV\n",
    "ofer.baharav@alumni.duke.edu â https://www.linkedin.com/in/oferbaharav Menlo Park, CA 415-305-1033\n",
    "  SUMMARY\n",
    "PROFESSIONAL EXPERIENCE\n",
    "  \n",
    "Product, engineering, and growth management leader passionate about building high quality products that customers love using.\n",
    "Over 15 years experience scaling technical products from vision to execution while managing operations, zero to one growth to\n",
    "$5M ARR, and teams of up to 30 employees. Provided leadership, analytical, and creative thinking for the design, build, launch,\n",
    "pilot, and scale of innovative products. Operated with focus on customer empathy, simple design, organizational impact, and\n",
    "global deployment. Maintained an amazing culture across the organization through agile methodology, leading teams for\n",
    "maximum impact. Coach and go-to person with management experience and excellent communication skills who is excited about\n",
    "helping and motivating team members to grow and excel in what they do best.\n",
    "  REALVR, Los Altos, CA\n",
    "Founder and Head of Product & Engineering\n",
    "Dec 2016 â Present\n",
    "l Designed and developed a cloud b2b platform for the creation of virtual reality walkthroughs for indoor spaces, increasingly using machine learning for optimizing the model to reach photorealistic results http://www.realvr.ai/hotel_lobby\n",
    "l Employed hardware/software including LiDAR, a camera rig, and photogrammetry for scanning while using ML vision for identifying scanned objects and then replacing them with 3D database assets, thereby cutting scan costs by 80% and resolving common scan blemishes to produce high fidelity photo grade 3D models\n",
    "l Trained company datasets using convolutional neural networks, deep learning, and transfer learning, constantly seeking to optimize classification and improve the modelâs accuracy using AutoML in Google Cloud Platform and AWS SageMaker\n",
    "l Built product using agile methodology: standups, weekly sprints, and continuous integration\n",
    "l Piloted prototype with enterprise clients for AR/VR immersive 3D walkthroughs. Presented at industry events. l Planned product vision, strategy, roadmap, and release cycles\n",
    "l Engineered machine learning algorithms in Python using Scikit-learn and TensorFlow\n",
    "APPLIED LAYERS, Palo Alto, CA Dec 2015 â May 2016 Founder and Head of Product & Engineering\n",
    "l Formed a team of 3 SaaS veterans with a vision for helping companies with sales predictions and recommendations using predictive analytics and Natural Language Processing\n",
    "l Validated a SaaS predictive analytics and machine learning engine with 3 pilots, to output predictions and recommendations for sales teams. The engine automatically analyzed CRM data for creating predictive models and generating recommendations for increasing sales closing rates.\n",
    "l Used cutting edge ML/AI algorithms to produce predictions and recommendations. Built reasoning into the system l After extensive conversations with investors decided to shelf the project\n",
    "CALLIX, SaÌo Paulo, Brazil Jul 2014 â Dec 2015 CEO and Head of Product & Engineering\n",
    "l Turned around this enterprise SaaS voice, analytics, and messaging call center platform, which was six months away from shut down prior to my arrival, when operations were in the red\n",
    "l Managed 30 employees and 15 direct reports including product and engineering. Held regular 1:1s and performance reviews l Fixed and scaled the existing platform, re-architecting the product and addressing technical debt on a shoestring budget\n",
    "l Increased server capacity to address burgeoning client load at peak usage hours, enabling seamless operations\n",
    "l From vision to execution, defined and built a new platform that scaled to millions of users, using the best in WebRTC, Ruby\n",
    "on Rails, and JavaScript, to form a unique click-to-call communications platform for e-commerce sales and customer\n",
    "support calls. Integrated external APIs such as Zendesk and Salesforce\n",
    "l Conducted rigorous piloting while iterating features and UX/UI based on user testing, metrics, and KPIs\n",
    "l Used agile methodology with daily standups, bi-weekly sprints and frequent shipping\n",
    "l Cut back features and costs by 50% by optimizing the product and deprecating less popular features and services\n",
    "l Reduced customer support tickets by 80% as a consequence of technical improvements and upgrades to the old platform\n",
    "l Reassigned underutilized technical support employees to technical sales, and built team of sales and customer success\n",
    "experts, leading first to break even and an overall increase in sales of 20%. Brought company into the black\n",
    "l Hired CFO and delivered dashboard KPIs to track daily progress for management and our investors\n",
    "l Developed and influenced enterprise client relations including LatAmâs largest insurance and telecom operators\n",
    "l Negotiated key contracts, agreements, and partnerships including with Latin Americaâs largest e-commerce, insurance, and\n",
    " \n",
    "telecom groups. Vetted contracts through legal, finance, and board of directors.\n",
    "l Presented product at industry events attracting PR coverage and demand for the new platform\n",
    "l Positioned product as an alternative to highly taxed traditional telephony solutions in Brazil and prepared global expansion l Successfully raised capital at a crucial time in the companyâs development\n",
    "l Brought the company to an exit, and returned back to the US for personal reasons\n",
    "PEER, Silicon Valley and SaÌo Paulo, Brazil Nov 2011 â July 2014 Founder and Head of Product\n",
    "l Launched live video and messaging networking application for professionals within 9 months in Nov 2013\n",
    "l Designed a new communications product for reconstructing video messaging conversations from asynchronous sources\n",
    "l Defined product roadmap and milestones including: wireframes, features, usability tests, prototypes, pilots and launches\n",
    "l Designed complex CoreOS architecture, hired expert iOS engineers to build in AVFoundation, AVKit, and Core Audio\n",
    "l Built the product in WebRTC, achieving high platform quality, positioning, and scale\n",
    "l Negotiated partnerships with university alumni networks to collaborate over a custom enterprise platform for this sector\n",
    "l Led small business development, marketing, and PR teams, reaching thousands of users\n",
    "l Launched mobile platform for buying and selling professional services using live video over LinkedInâs social graph\n",
    "l Raised capital, hired software engineers and UX/UI designers, built product roadmap, enrolled company in highly selective\n",
    "LatAm accelerator, and negotiated key partnerships and legal contracts\n",
    "l Represented company as panelist at conferences. Company won competitions and awards, including Mobile World Congress\n",
    "JOHNNY LABS, Palo Alto, CA May 2010 â Present EIR\n",
    "l As EIR at prominent Silicon Valley accelerators, was interim CXO and product advisor to several enterprise SaaS startups. Participated in funding and mergers and acquisition negotiations.\n",
    "BRIMACOMB & ASSOCIATES LLC, Palo Alto, CA Partner\n",
    "l Established and managed West Coast office for Brimacomb & Associates, a $30M VC fund and Venture Advisory l Worked with client CEOs in operations, strategy, and fund raising\n",
    "l Helped with product, operations, growth and strategy, and negotiated complex contracts on behalf of clients\n",
    "DOW JONES & COMPANY, San Francisco, CA Manager\n",
    "l Managed a team of five Account Executives to sell VentureSource SaaS analytics and services to venture capital general and limited partners, and investment bankers, exceeding quota by 200%\n",
    "ALFY, INC., New York, NY\n",
    "Vice President of Business Development\n",
    "l Formed all principal business development partnerships, and led company to recognized player in its sector l Instrumental in raising $42M in three rounds of funding\n",
    "l Managed a team of 4 business development managers\n",
    "EDUCATION\n",
    "MBA, Global Management and Finance, Graduated 2007\n",
    "Duke University, The Fuqua School of Business, Durham, NC\n",
    "Elected Chair of Speaker Committee and successfully led the process with Mexicoâs former president Vicente Fox, who spoke at commencement\n",
    "Bachelor of Science, Information Systems; Graduated with Honors, 2002 University of Phoenix\n",
    "NOTEWORTHY\n",
    "l Intermediate Python machine learning programming skills; Fluent in English, Portuguese, and Hebrew\n",
    "l EIR, advisor, and mentor at prominent Silicon Valley accelerators and startups 2008 â 2010, and 2015 â 2019 (recently at\n",
    "Google Launchpad and Alchemist, also working with ML based tech transfer from Israel to Brazil with two agtech startups) l Neural Networks and Deep Learning concentration on Coursera (5 courses/ 8 mo curriculum). Certificates earned May, 2018 l Lambda School Machine Learning and Artificial Intelligence: 1.5 year course for ML engineering in Python (night class)\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity of my resume to job descriptions in dataset\n",
    "new = tfidf.transform(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1174 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 169 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.16715447, 1.17066331, 1.17125045, 1.18905458, 1.18905458]]),\n",
       " array([[385, 215,  83,  27,  66]]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Coursera was founded by two computer science professors at Stanford with a vision of providing life-transforming learning experiences to anyone anywhere It is the world\\xe2\\x80\\x99s largest online learning platform for higher education In partnership with 170 of the world\\xe2\\x80\\x99s top universities and industry educators we offer courses Specializations and degrees that empower over 40 million learners around the world to achieve their career goals Over 1800 companies use the company\\xe2\\x80\\x99s enterprise platform Coursera for Business to transform their talent And we are backed by leading venture capital firms such as Kleiner Perkins Caufield & Byers New Enterprise Associates and GSV Capital  At Coursera our Data Science team is helping to build the future of education through data-driven decision making and data-powered products We drive product and business strategy through measurement experimentation and causal inference We define develop and launch the models and algorithms that power content discovery personalized learning and machine-assisted teaching and grading We believe the next generation of teaching and learning should be personalized accessible and efficient With our scale data technology and talent Coursera and its Data Science team are positioned to make that vision a reality  As Senior Data Scientist Machine Learning you will define and build innovative data-powered products to personalize and scale high-quality experiences for 40 million global learners The ideal candidate possesses a strong statistical and computational skill set is collaborative and impact-driven and shares our passion for education Your responsibilities Ideate prototype and productionize the machine learning algorithms that power Coursera\\xe2\\x80\\x99s product including discovery eg personalized recommendations learning eg automated study guides targeted nudges and instructor-facing features to support learners at scale eg machine-assisted grading and feedback Work cross-functionally with engineers product managers and other data scientists on our core discovery and learning products Your skills Solid background in applied math computer science statistics or related technical field Deep applied statistics and modeling skills Strong computational skills Proficient with at least one scripting language eg Python and at least one statistical software package Excellent communication and project management skills 3+ years of industry experience preferred If this opportunity interests you you might like these courses on Coursera Recommender Systems Machine Learning'\n"
     ]
    }
   ],
   "source": [
    "print(data.cleaned_text[385])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Company Profile  Morgan Stanley is a leading global financial services firm providing a wide range of investment banking securities investment management and wealth management services The Firm's employees serve clients worldwide including corporations governments and individuals from more than 1200 offices in 43 countries As a market leader the talent and passion of our people is critical to our success Together we share a common set of values rooted in integrity excellence and strong team ethic Morgan Stanley can provide a superior foundation for building a professional career - a place for people to learn to achieve and grow A philosophy that balances personal lifestyles perspectives and needs is an important part of our culture  Technology  Technology works as a strategic partner with Morgan Stanley business units and the world's leading technology companies to redefine how we do business in ever more global complex and dynamic financial markets Morgan Stanley's sizeable investment in technology results in quantitative trading systems cutting-edge modelling and simulation software comprehensive risk and security systems and robust client-relationship capabilities plus the worldwide infrastructure that forms the backbone of these systems and tools Our insights our applications and infrastructure give a competitive edge to clients' businesses and to our own  MS Investment Management IMIT Technology  Morgan Stanley Investment Management Technology IMIT exclusively partners with the Morgan Stanley Investment Management MSIM business division to design and develop systems and integrate vendor products to globally support full life cycle business processing Activities include Portfolio Analysis Risk Trading Operations and Sales & Marketing Morgan Stanley Investment Management MSIM Technology also provides holistic support and quality assurance across the suite of applications used in the MSIM environment  The IMIT Sales Technology team owns Sales & Distribution technology platform The team is responsible for defining technology strategy in-line with business goals and providing solutions in a very dynamic environment Sales Platform is a distributed system with several integrated components providing customized CRM functionality data process integration with firm systems business intelligence through Reporting & Analytics and  data driven Marketing & Lead GenerationOverview We are looking for an experienced Data Scientist to join our data-science group The person in this role would be responsible for analyzing data and developing predictive models for various use-cases within Sales & Marketing such as Sales Targeting & Segmentation Lead Generation Product Recommendation etc They must have strong experience employing different data mining   data analysis methods using a variety of data tools building and implementing models They must have a proven ability to drive business results with their data-based insights The ideal candidate is adept at discovering and using wide variety of data-sets together It is absolutely critical that they are comfortable understanding the business domain and interpreting   explaining the findings of models as it applies to the business problem for people outside  data-science domainResponsibilities  Work with stakeholders identifying opportunities  for leveraging data to solve for business challenges\\xc2\\xb7Identify valuable data sources   data sets that can be leveraged to improve results   Analyze data to interpret against business  opportunity and discover trends and patterns   Process cleanse and verify the integrity of  structured   un-structured data used for analysis   Research and implement custom statistical models  and machine learning algorithms   Execute analytical experiments  Qualifications \\xc2\\xb7 Master\\xe2\\x80\\x99s Degree in Computer Science Statistics Applied Math or relevant field  \\xc2\\xb7 7+ year\\xe2\\x80\\x99s practical experience as a Data Scientist with proven track record  \\xc2\\xb7 Strong math skills eg statistics algebra multi-variable calculus  \\xc2\\xb7 Expertise with R SQL and Python familiarity with Scala Java or C++ is an asset  \\xc2\\xb7 Extensive background in data mining and statistical analysis  \\xc2\\xb7 Deep understanding of real-life applicability and limitations of machine-learning algorithms  \\xc2\\xb7 Problem-solving aptitude  \\xc2\\xb7 Analytical mind and business acumen  \\xc2\\xb7 Excellent communication and presentation skills  Skills and Experience\\xc2\\xb7Experience with B2B Financial Industry Asset Management Sales & Marketing is highly desired \\xc2\\xb7Knowledge of a variety of machine learning techniques clustering decision tree learning artificial neural networks etc and their real-world advantages drawbacks   Knowledge  of advanced statistical techniques and concepts regression properties of distributions statistical tests and proper usage etc and experience with applications   Knowledge  and experience in statistical and data mining techniquesGLM Regression Random Forest Boosting Trees text mining social network analysis etc   Expertise  querying Relational   No-SQL databases and using statistical programming languages like R Python etc   Experience  with distributed data computing toolsHadoop Hive Spark etc  Experience visualizing presenting data for stakeholders  usingBusiness Objects Tableau D3js ggplot etc   Experience  with data-science tools Dataiku Jupyter etc   Knowledge  of open-source 3rd party cloud based data science   NLP   machine learning platforms eg AWS or Azure offerings\"\n"
     ]
    }
   ],
   "source": [
    "print(data.cleaned_text[215])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
